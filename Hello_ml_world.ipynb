{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 14:14:28.661959: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 160s 85ms/step - loss: 0.2036 - accuracy: 0.9393\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9778\n",
      "Test accuracy: 0.9778000116348267\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp88v0oi92/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp88v0oi92/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model saved as handwritten_digits_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iamme/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2024-05-24 14:19:08.452719: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-24 14:19:08.452782: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-24 14:19:08.454099: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp88v0oi92\n",
      "2024-05-24 14:19:08.458729: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-05-24 14:19:08.458777: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp88v0oi92\n",
      "2024-05-24 14:19:08.461880: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-05-24 14:19:08.474914: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2024-05-24 14:19:08.478926: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-24 14:19:08.630392: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp88v0oi92\n",
      "2024-05-24 14:19:08.652507: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 198416 microseconds.\n",
      "2024-05-24 14:19:08.719761: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset_gen():\n",
    "    for data in x_test[:100]:\n",
    "        data = data.astype(np.float32)\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        yield [data]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"handwritten_digits_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Quantized model saved as handwritten_digits_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv2d, layer type: Conv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 8]\n",
      "Layer name: max_pooling2d, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 8]], output shape: [None, 13, 13, 8]\n",
      "Layer name: conv2d_1, layer type: Conv2D, input shapes: [[None, 13, 13, 8]], output shape: [None, 11, 11, 16]\n",
      "Layer name: max_pooling2d_1, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 16]], output shape: [None, 5, 5, 16]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 5, 5, 16]], output shape: [None, 400]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 400]], output shape: [None, 64]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 10]\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv2d, layer type: Conv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 8]\n",
      "Layer name: max_pooling2d, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 8]], output shape: [None, 13, 13, 8]\n",
      "Layer name: conv2d_1, layer type: Conv2D, input shapes: [[None, 13, 13, 8]], output shape: [None, 11, 11, 16]\n",
      "Layer name: max_pooling2d_1, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 16]], output shape: [None, 5, 5, 16]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 5, 5, 16]], output shape: [None, 400]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 400]], output shape: [None, 64]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 10]\n",
      "Creating HLS model\n",
      "WARNING: Layer conv2d requires \"dataflow\" pipeline style. Switching to \"dataflow\" pipeline style.\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Vivado HLS installation not found. Make sure \"vivado_hls\" is on PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m hls_model\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Generate the Verilog code and testbench\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m hls_model\u001b[38;5;241m.\u001b[39mbuild(reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, csim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, synth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, vsynth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, export\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cosim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Prepare input data for simulation\u001b[39;00m\n\u001b[1;32m     33\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hls4ml/model/graph.py:871\u001b[0m, in \u001b[0;36mModelGraph.build\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_output_dir()):\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;66;03m# Assume the project wasn't written before\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite()\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hls4ml/backends/vivado/vivado_backend.py:203\u001b[0m, in \u001b[0;36mVivadoBackend.build\u001b[0;34m(self, model, reset, csim, synth, cosim, validation, export, vsynth, fifo_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m     found \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommand -v vivado_hls > /dev/null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m found \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVivado HLS installation not found. Make sure \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvivado_hls\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on PATH.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    205\u001b[0m curr_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m    206\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_output_dir())\n",
      "\u001b[0;31mException\u001b[0m: Vivado HLS installation not found. Make sure \"vivado_hls\" is on PATH."
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import numpy as np\n",
    "\n",
    "# Configure HLS4ML\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
    "config['Model']['ReuseFactor'] = 1\n",
    "\n",
    "# Set layer-specific settings\n",
    "for layer in model.layers:\n",
    "    layer_config = config.get(layer.name, {})\n",
    "    if isinstance(layer, tf.keras.layers.Dense):\n",
    "        layer_config['Strategy'] = 'Resource'\n",
    "        layer_config['Precision'] = {}\n",
    "        layer_config['Precision']['weight'] = 'ap_fixed<16,6>'\n",
    "        layer_config['Precision']['bias'] = 'ap_fixed<16,6>'\n",
    "        layer_config['Precision']['result'] = 'ap_fixed<16,6>'\n",
    "    elif isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer_config['Precision'] = {}\n",
    "        layer_config['Precision']['weight'] = 'ap_fixed<16,6>'\n",
    "        layer_config['Precision']['bias'] = 'ap_fixed<16,6>'\n",
    "        layer_config['Precision']['result'] = 'ap_fixed<16,6>'\n",
    "        layer_config['ReuseFactor'] = 1\n",
    "    config[layer.name] = layer_config\n",
    "\n",
    "# Convert the model to Verilog\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model, hls_config=config)\n",
    "hls_model.compile()\n",
    "\n",
    "# Generate the Verilog code and testbench\n",
    "hls_model.build(reset=False, csim=False, synth=True, vsynth=True, export=True, cosim=False)\n",
    "\n",
    "# Prepare input data for simulation\n",
    "num_samples = 100\n",
    "x_test_sim = x_test[:num_samples]\n",
    "y_test_sim = y_test[:num_samples]\n",
    "\n",
    "# Run Vivado simulation and get the output\n",
    "hls4ml.report.vivado_report(hls_model, x_test_sim, y_test_sim, show_outputs=True)\n",
    "\n",
    "print(\"Verilog code generated and testbench simulation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
